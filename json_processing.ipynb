{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T22:19:18.870655Z",
     "start_time": "2018-11-25T22:19:18.491195Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import os\n",
    "from datetime import timedelta, date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T22:19:19.793355Z",
     "start_time": "2018-11-25T22:19:19.778197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/storage2/Git/jooble-ir-2018-paper/Data/by'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from paper.config import *\n",
    "\n",
    "by_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T22:19:22.590379Z",
     "start_time": "2018-11-25T22:19:22.354324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101775\n"
     ]
    }
   ],
   "source": [
    "by_dir = \"/mnt/storage2/Data/by\"\n",
    "list_json = []\n",
    "\n",
    "start_date = date(2017, 3, 1)\n",
    "# end_date = date(2017, 1, 30)\n",
    "end_date = date(2017, 3, 3)\n",
    "\n",
    "date_range = pd.date_range(start_date, end_date)\n",
    "\n",
    "#looping through all days from 2017_01_1 to 2017_01_30 with step = 1 day\n",
    "for single_date in date_range:\n",
    "    date_ = single_date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    #!!!!CHANGE PATH!!!!!!\n",
    "    file_job = os.path.join(by_dir, 'by_job_{}.json.gz'.format(date_))\n",
    "    file_job_text = os.path.join(by_dir, 'by_job_text_{}.json.gz'.format(date_))\n",
    "\n",
    "    #reading two files simuntaneously\n",
    "    document_job, document_job_text = [],[]\n",
    "    \n",
    "    with gzip.open(file_job, \"rb\") as f1, gzip.open(file_job_text, \"rb\") as f2: \n",
    "        for line1, line2 in zip(f1, f2):\n",
    "            vacation_job = json.loads(line1)\n",
    "            vacation_job_text = json.loads(line2)\n",
    "            document_job.append(vacation_job)\n",
    "            document_job_text.append(vacation_job_text)\n",
    "\n",
    "        #creating a list of dictionaries\n",
    "        for i in range(len(document_job)):\n",
    "            for j in range(len(document_job_text)):\n",
    "                if document_job[i]['id'] == document_job_text[j]['id_job']:\n",
    "                    data = {}\n",
    "                    data['id'] = document_job[i]['id']\n",
    "                    data['lang_text'] = document_job[i]['lang_text']\n",
    "                    data['lang_title'] = document_job[i]['lang_title']\n",
    "                    data['company_name'] = document_job[i]['company_name']\n",
    "                    data['title'] = document_job[i]['title']\n",
    "                    data['title_normalized'] = document_job[i]['title_normalized']\n",
    "                    data['salary_val1'] = document_job[i]['salary_val1']\n",
    "                    data['salary_val2'] = document_job[i]['salary_val2']\n",
    "                    data['company_name'] = document_job[i]['company_name']\n",
    "                    data['url'] = document_job[i]['url']\n",
    "                    \n",
    "                    data['text'] = document_job_text[j]['text']\n",
    "                    list_json.append(data)\n",
    "                    \n",
    "print(len(list_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /mnt/storage2/Git/jooble-ir-2018-paper/Data/by/by_job_2017-03-02.json.gz: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! cat /mnt/storage2/Git/jooble-ir-2018-paper/Data/by/by_job_2017-03-02.json.gz\n",
    "! Data/by/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemm_d: 1996.782083272934\n"
     ]
    }
   ],
   "source": [
    "from paper.analyze import norm_stem_lang\n",
    "from paper.analyze import normalize\n",
    "\n",
    "\n",
    "@timed\n",
    "def stemm_d(list_json):\n",
    "    # stemmed = [norm_stem_lang(doc['title']+ ' ' + doc['text']).split() for doc in list_json]\n",
    "    stemmed = []\n",
    "    for doc in list_json:\n",
    "        try:\n",
    "            stemmed.append(norm_stem_lang(doc['title']+ ' ' + doc['text']).split())\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "stemm_d(list_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# stemmed[25:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': '',\n",
       " 'id': '-4161554798960957173',\n",
       " 'lang_text': 'ru',\n",
       " 'lang_title': 'ru',\n",
       " 'salary_val1': '',\n",
       " 'salary_val2': '',\n",
       " 'text': 'Требуется SEO специалист знающий специфику продвижения в США, требуется подвинуть сайт по 2-3 ВЧ запросам по одному штату.',\n",
       " 'title': 'SEO-оптимизатор. Продвижение сайта в США (удаленно)',\n",
       " 'title_normalized': 'seo оптимизатор продвижение сайта в сша удаленно',\n",
       " 'url': 'https://www.fl.ru/projects/3085129/prodvijenie-sayta-v-ssha-.html?utm_source=joobleby&utm_medium=cpc&utm_campaign=jooble'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_json[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_json[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update_timed: 33.62377214431763\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "from paper import index\n",
    "from paper.utils import timed\n",
    "\n",
    "@timed\n",
    "def update_timed(list_json, stemmed):\n",
    "    index.update_index(list_json, stemmed)\n",
    "\n",
    "# index.delete_all()\n",
    "update_timed(list_json, stemmed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'10046',\n",
       " b'1047',\n",
       " b'1196',\n",
       " b'122',\n",
       " b'127',\n",
       " b'1427',\n",
       " b'1700',\n",
       " b'1724',\n",
       " b'2082',\n",
       " b'2164',\n",
       " b'2262',\n",
       " b'239',\n",
       " b'2507',\n",
       " b'2557',\n",
       " b'2628',\n",
       " b'2677',\n",
       " b'2696',\n",
       " b'2874',\n",
       " b'292',\n",
       " b'2998',\n",
       " b'3050',\n",
       " b'3252',\n",
       " b'3309',\n",
       " b'3461',\n",
       " b'3623',\n",
       " b'3766',\n",
       " b'3961',\n",
       " b'4058',\n",
       " b'4472',\n",
       " b'4880',\n",
       " b'4893',\n",
       " b'5230',\n",
       " b'5278',\n",
       " b'5364',\n",
       " b'5404',\n",
       " b'5676',\n",
       " b'5882',\n",
       " b'5969',\n",
       " b'6131',\n",
       " b'6144',\n",
       " b'6541',\n",
       " b'6571',\n",
       " b'6823',\n",
       " b'7058',\n",
       " b'7154',\n",
       " b'7217',\n",
       " b'7761',\n",
       " b'781',\n",
       " b'7885',\n",
       " b'8',\n",
       " b'8035',\n",
       " b'8516',\n",
       " b'866',\n",
       " b'8992',\n",
       " b'9050',\n",
       " b'9368',\n",
       " b'9509',\n",
       " b'966',\n",
       " b'9695'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from redis import Redis\n",
    "\n",
    "\n",
    "tokens = [\"inv+ \"+tok for tok in ['водител', 'такс']]\n",
    "r = Redis()\n",
    "r.sinter(*tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting redis==2.10.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/f6/7a76333cf0b9251ecf49efff635015171843d9b977e4ffcf59f9c4428052/redis-2.10.6-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.1MB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: redis\n",
      "  Found existing installation: redis 3.0.0.post1\n",
      "    Uninstalling redis-3.0.0.post1:\n",
      "      Successfully uninstalled redis-3.0.0.post1\n",
      "Successfully installed redis-2.10.6\n"
     ]
    }
   ],
   "source": [
    "! pip install redis==2.10.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from paper.index import get_docs\n",
    "\n",
    "get_docs([1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Index update via `updater` service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from paper.utils import post_request as post\n",
    "from paper.index import delete_all\n",
    "\n",
    "delete_all()\n",
    "\n",
    "update_json = {'docs': list_json[100:200]}\n",
    "\n",
    "post(UPDATER_PORT, UPDATER_PATH, update_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
